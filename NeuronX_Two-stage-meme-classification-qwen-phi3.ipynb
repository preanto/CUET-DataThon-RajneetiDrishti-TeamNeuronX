{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4baf302c",
   "metadata": {},
   "source": [
    "# CUET CSE FEST 2025\n",
    "## PoliMemeDecode: Humor That Speaks Politics\n",
    "\n",
    "**Competition:** Political Meme Classification Challenge  \n",
    "**Task:** Classify Bangla memes as **Political** or **NonPolitical**\n",
    "\n",
    "**Dataset:** https://www.kaggle.com/datasets/shahriar26s/meme-dataset\n",
    "\n",
    "---\n",
    "\n",
    "### Two-Stage Classification Pipeline\n",
    "- **Stage 1:** Qwen2.5-VL-7B-Instruct (4-bit quantized) for initial classification\n",
    "- **Stage 2:** Phi-3-Vision-128k-Instruct for keyword-based validation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66076e7",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "Install required libraries: transformers, bitsandbytes for quantization, and image processing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9265ce73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:25:09.282510Z",
     "iopub.status.busy": "2025-12-05T09:25:09.281794Z",
     "iopub.status.idle": "2025-12-05T09:26:31.572875Z",
     "shell.execute_reply": "2025-12-05T09:26:31.571974Z",
     "shell.execute_reply.started": "2025-12-05T09:25:09.282481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hLibraries installed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install Required Libraries\n",
    "# Use bitsandbytes for 4-bit quantization to fit on T4 GPU\n",
    "!pip install transformers accelerate bitsandbytes -q\n",
    "!pip install pandas pillow tqdm -q\n",
    "!pip install qwen-vl-utils -q\n",
    "print(\"Libraries installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba3f88",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "Import PyTorch, transformers, pandas, PIL for image handling, and check GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275dd0ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:26:31.575032Z",
     "iopub.status.busy": "2025-12-05T09:26:31.574811Z",
     "iopub.status.idle": "2025-12-05T09:27:02.250884Z",
     "shell.execute_reply": "2025-12-05T09:27:02.250187Z",
     "shell.execute_reply.started": "2025-12-05T09:26:31.575007Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-05 09:26:45.748729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764926805.978552      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764926806.094383      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: Tesla P100-PCIE-16GB\n",
      "GPU Memory: 17.1 GB\n",
      "\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "\n",
    "# Check GPU\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Memory: {gpu_mem:.1f} GB\")\n",
    "\n",
    "print(\"\\nLibraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55e321",
   "metadata": {},
   "source": [
    "### Define Paths\n",
    "Configure paths for test images, annotated CSV dataset, and output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949aa62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:02.252110Z",
     "iopub.status.busy": "2025-12-05T09:27:02.251663Z",
     "iopub.status.idle": "2025-12-05T09:27:02.258118Z",
     "shell.execute_reply": "2025-12-05T09:27:02.256416Z",
     "shell.execute_reply.started": "2025-12-05T09:27:02.252091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths configured:\n",
      "   Images: /kaggle/input/poli-meme-decode-cuet-cse-fest/PoliMemeDecode/Test/Image\n",
      "   CSV: /kaggle/input/meme-dataset/merged_meme_data.csv\n",
      "   Output: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define Paths\n",
    "# =============================================\n",
    "# UPDATE THESE PATHS ACCORDING TO YOUR UPLOAD\n",
    "# =============================================\n",
    "\n",
    "# Test images from competition dataset\n",
    "IMAGE_DIR = \"/kaggle/input/poli-meme-decode-cuet-cse-fest/PoliMemeDecode/Test/Image\"\n",
    "\n",
    "# Your custom uploaded CSV with annotations\n",
    "# CHANGE THIS PATH to match your custom dataset upload name\n",
    "ANNOTATED_CSV_PATH = \"/kaggle/input/meme-dataset/merged_meme_data.csv\"\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "SUBMISSION_PATH = f\"{OUTPUT_DIR}/submission.csv\"\n",
    "CHECKPOINT_PATH = f\"{OUTPUT_DIR}/prediction_checkpoint.csv\"\n",
    "STAGE2_CHECKPOINT_PATH = f\"{OUTPUT_DIR}/stage2_checkpoint.csv\"\n",
    "\n",
    "print(\"Paths configured:\")\n",
    "print(f\"   Images: {IMAGE_DIR}\")\n",
    "print(f\"   CSV: {ANNOTATED_CSV_PATH}\")\n",
    "print(f\"   Output: {SUBMISSION_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec97d0",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "Load annotated CSV with Bangla text encoding and display dataset statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa8014f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:02.259291Z",
     "iopub.status.busy": "2025-12-05T09:27:02.259018Z",
     "iopub.status.idle": "2025-12-05T09:27:02.327431Z",
     "shell.execute_reply": "2025-12-05T09:27:02.326842Z",
     "shell.execute_reply.started": "2025-12-05T09:27:02.259266Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotated CSV...\n",
      "\n",
      "Dataset Info:\n",
      "   Total records: 330\n",
      "   Columns: ['Image_name', 'extracted_text', 'Language', 'Humor', 'Metaphor', 'Meme_Explanation', 'Metaphor_Object', 'Political_Intensity']\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Humor</th>\n",
       "      <th>Metaphor</th>\n",
       "      <th>Meme_Explanation</th>\n",
       "      <th>Metaphor_Object</th>\n",
       "      <th>Political_Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0001.jpg</td>\n",
       "      <td>*Looses Ducsu Election\\n- Any comment on the e...</td>\n",
       "      <td>English</td>\n",
       "      <td>Ironic</td>\n",
       "      <td>Both</td>\n",
       "      <td>This meme satirizes Bangladeshi politician Nur...</td>\n",
       "      <td>Ducsu Election</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test0002.jpg</td>\n",
       "      <td>kya matlab ke fue</td>\n",
       "      <td>Banglish</td>\n",
       "      <td>Mockery</td>\n",
       "      <td>Both</td>\n",
       "      <td>This reaction meme features an image of a disa...</td>\n",
       "      <td>Relatable social reaction</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test0003.jpg</td>\n",
       "      <td>SNACKS MUJIB DURING\\n15TH AUG SEHR!</td>\n",
       "      <td>Banglish</td>\n",
       "      <td>Mockery</td>\n",
       "      <td>Both</td>\n",
       "      <td>This meme satirizes individuals who overeat at...</td>\n",
       "      <td>15th Aug</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test0004.jpg</td>\n",
       "      <td>No one:\\nAbsolutely no one;\\nRandom এনসিপি/বাগ...</td>\n",
       "      <td>Bangla</td>\n",
       "      <td>Mockery</td>\n",
       "      <td>Text</td>\n",
       "      <td>This meme satirizes pro-government student win...</td>\n",
       "      <td>বাগছাস / শিবির (BCL / Shibir)</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test0005.jpg</td>\n",
       "      <td>বন্ধু: বিকাশের নতুন আপডেট দেখসস? অনেক নতুন ফিচ...</td>\n",
       "      <td>Bangla</td>\n",
       "      <td>Ironic</td>\n",
       "      <td>Both</td>\n",
       "      <td>This meme humorously describes the feeling of ...</td>\n",
       "      <td>Low account balance</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_name                                     extracted_text  Language  \\\n",
       "0  test0001.jpg  *Looses Ducsu Election\\n- Any comment on the e...   English   \n",
       "1  test0002.jpg                                  kya matlab ke fue  Banglish   \n",
       "2  test0003.jpg                SNACKS MUJIB DURING\\n15TH AUG SEHR!  Banglish   \n",
       "3  test0004.jpg  No one:\\nAbsolutely no one;\\nRandom এনসিপি/বাগ...    Bangla   \n",
       "4  test0005.jpg  বন্ধু: বিকাশের নতুন আপডেট দেখসস? অনেক নতুন ফিচ...    Bangla   \n",
       "\n",
       "     Humor Metaphor                                   Meme_Explanation  \\\n",
       "0   Ironic     Both  This meme satirizes Bangladeshi politician Nur...   \n",
       "1  Mockery     Both  This reaction meme features an image of a disa...   \n",
       "2  Mockery     Both  This meme satirizes individuals who overeat at...   \n",
       "3  Mockery     Text  This meme satirizes pro-government student win...   \n",
       "4   Ironic     Both  This meme humorously describes the feeling of ...   \n",
       "\n",
       "                 Metaphor_Object Political_Intensity  \n",
       "0                 Ducsu Election                High  \n",
       "1      Relatable social reaction                 Low  \n",
       "2                       15th Aug                High  \n",
       "3  বাগছাস / শিবির (BCL / Shibir)                High  \n",
       "4            Low account balance                 Low  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Statistics:\n",
      "   Image_name: 330/330 non-null\n",
      "   extracted_text: 330/330 non-null\n",
      "   Language: 330/330 non-null\n",
      "   Humor: 330/330 non-null\n",
      "   Metaphor: 330/330 non-null\n",
      "   Meme_Explanation: 330/330 non-null\n",
      "   Metaphor_Object: 330/330 non-null\n",
      "   Political_Intensity: 330/330 non-null\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load and Explore CSV Data\n",
    "print(\"Loading annotated CSV...\")\n",
    "\n",
    "# Load with UTF-8-sig encoding for Bangla text\n",
    "try:\n",
    "    df = pd.read_csv(ANNOTATED_CSV_PATH, encoding='utf-8-sig')\n",
    "except:\n",
    "    df = pd.read_csv(ANNOTATED_CSV_PATH, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nDataset Info:\")\n",
    "print(f\"   Total records: {len(df)}\")\n",
    "print(f\"   Columns: {df.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nColumn Statistics:\")\n",
    "for col in df.columns:\n",
    "    non_null = df[col].notna().sum()\n",
    "    print(f\"   {col}: {non_null}/{len(df)} non-null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b722063",
   "metadata": {},
   "source": [
    "### Verify Images\n",
    "Check that all images referenced in the CSV exist in the image directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd02fae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:02.329658Z",
     "iopub.status.busy": "2025-12-05T09:27:02.329375Z",
     "iopub.status.idle": "2025-12-05T09:27:02.348595Z",
     "shell.execute_reply": "2025-12-05T09:27:02.348002Z",
     "shell.execute_reply.started": "2025-12-05T09:27:02.329632Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying images...\n",
      "   Images in directory: 330\n",
      "   Matched: 330\n",
      "   Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Verify Images Exist\n",
    "print(\"Verifying images...\")\n",
    "\n",
    "if os.path.exists(IMAGE_DIR):\n",
    "    image_files = os.listdir(IMAGE_DIR)\n",
    "    print(f\"   Images in directory: {len(image_files)}\")\n",
    "\n",
    "    # Check matching\n",
    "    csv_images = set(df['Image_name'].tolist())\n",
    "    dir_images = set(image_files)\n",
    "\n",
    "    matched = csv_images.intersection(dir_images)\n",
    "    missing = csv_images - dir_images\n",
    "\n",
    "    print(f\"   Matched: {len(matched)}\")\n",
    "    print(f\"   Missing: {len(missing)}\")\n",
    "\n",
    "    if missing:\n",
    "        print(f\"\\nMissing images: {list(missing)[:10]}...\")\n",
    "else:\n",
    "    print(f\"Image directory not found: {IMAGE_DIR}\")\n",
    "    print(\"   Make sure the competition dataset is added to inputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc386a1",
   "metadata": {},
   "source": [
    "### Chain-of-Thought Prompt\n",
    "Define CoT prompt template using meme metadata (humor, metaphor, political intensity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98264021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:02.349436Z",
     "iopub.status.busy": "2025-12-05T09:27:02.349262Z",
     "iopub.status.idle": "2025-12-05T09:27:02.356059Z",
     "shell.execute_reply": "2025-12-05T09:27:02.355358Z",
     "shell.execute_reply.started": "2025-12-05T09:27:02.349422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoT prompt template defined!\n",
      "\n",
      "Sample prompt preview:\n",
      "You are an expert meme analyst. Analyze this Bangla/Bengali meme and classify it as either \"Political\" or \"NonPolitical\".\n",
      "\n",
      "## CONTEXT FROM ANALYSIS:\n",
      "- **Image**: test0001.jpg\n",
      "- **Humor Type**: Ironic\n",
      "- **Metaphor Location**: Both\n",
      "- **Meme Explanation**: This meme satirizes Bangladeshi politician Nurul Haque Nur's iconic quote, 'I'm a bit disappointed,' which he famously said after the chaotic 2019 DUCSU (Dhaka University Central Students' Union) election. The humor comes from applying this massive understatement to the dramatic situation of losing a significant political race.\n",
      "- **Key Metaphor Object**: Ducsu Election\n",
      "- **Political Intensity**: High\n",
      "\n",
      "## CLASSIFICATION CRITERIA:\n",
      "\n",
      "### Political Indicators (classify as \"Political\"):\n",
      "- Political figures (Sheikh Hasina, Khaleda Zia, politicians...\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define Chain-of-Thought Prompt Template\n",
    "# Uses underscore column names: Meme_Explanation, Metaphor_Object, Political_Intensity\n",
    "\n",
    "def create_cot_prompt(row):\n",
    "    \"\"\"\n",
    "    Create a Chain-of-Thought prompt using CSV data for the image.\n",
    "    Column names with underscores as in predict.csv.\n",
    "    \"\"\"\n",
    "    image_name = row.get('Image_name', 'Unknown')\n",
    "    humor = row.get('Humor', 'Unknown')\n",
    "    metaphor = row.get('Metaphor', 'Unknown')\n",
    "    meme_explanation = row.get('Meme_Explanation', 'Not provided')\n",
    "    metaphor_object = row.get('Metaphor_Object', 'Not provided')\n",
    "    political_intensity = row.get('Political_Intensity', 'Unknown')\n",
    "    \n",
    "    prompt = f\"\"\"You are an expert meme analyst. Analyze this Bangla/Bengali meme and classify it as either \"Political\" or \"NonPolitical\".\n",
    "\n",
    "## CONTEXT FROM ANALYSIS:\n",
    "- **Image**: {image_name}\n",
    "- **Humor Type**: {humor}\n",
    "- **Metaphor Location**: {metaphor}\n",
    "- **Meme Explanation**: {meme_explanation}\n",
    "- **Key Metaphor Object**: {metaphor_object}\n",
    "- **Political Intensity**: {political_intensity}\n",
    "\n",
    "## CLASSIFICATION CRITERIA:\n",
    "\n",
    "### Political Indicators (classify as \"Political\"):\n",
    "- Political figures (Sheikh Hasina, Khaleda Zia, politicians)\n",
    "- Political parties (BNP, Awami League, BCL, Shibir)\n",
    "- Government, parliament, elections, voting\n",
    "- Protests, hartals, political movements\n",
    "- Corruption, political scandals\n",
    "- Political Intensity is \"High\" strongly suggests Political\n",
    "\n",
    "### Non-Political Indicators (classify as \"NonPolitical\"):\n",
    "- Daily life humor (exams, jobs, relationships)\n",
    "- Entertainment (cricket, movies, celebrities)\n",
    "- Social situations without political context\n",
    "- Political Intensity is \"Low\" strongly suggests NonPolitical\n",
    "\n",
    "## DECISION LOGIC:\n",
    "1. If Political_Intensity is \"High\" likely Political\n",
    "2. If Political_Intensity is \"Low\" likely NonPolitical  \n",
    "3. If Metaphor_Object contains political keywords Political\n",
    "4. Otherwise analyze the meme context\n",
    "\n",
    "## OUTPUT:\n",
    "Based on the context and image, provide your classification:\n",
    "\n",
    "FINAL_ANSWER: [Political or NonPolitical]\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "print(\"CoT prompt template defined!\")\n",
    "print(\"\\nSample prompt preview:\")\n",
    "sample_prompt = create_cot_prompt(df.iloc[0])\n",
    "print(sample_prompt[:800] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd9480",
   "metadata": {},
   "source": [
    "---\n",
    "# STAGE 1: Initial Classification (Qwen2.5-VL)\n",
    "### Load Qwen Model\n",
    "Load Qwen2.5-VL-7B-Instruct with 4-bit NF4 quantization for T4 GPU (~8GB VRAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a4d948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:02.357135Z",
     "iopub.status.busy": "2025-12-05T09:27:02.356798Z",
     "iopub.status.idle": "2025-12-05T09:27:02.375902Z",
     "shell.execute_reply": "2025-12-05T09:27:02.375099Z",
     "shell.execute_reply.started": "2025-12-05T09:27:02.357117Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Load Qwen2.5-VL Model (Optimized for Free Tier T4 GPU)\n",
    "# USE GPU T4 x2 on Kaggle for best results!\n",
    "\n",
    "def load_qwen_model():\n",
    "    \"\"\"\n",
    "    Load Qwen2.5-VL-7B-Instruct with 4-bit quantization for Kaggle free tier.\n",
    "    Uses ~8GB VRAM with 4-bit, works on T4 (16GB).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LOADING QWEN2.5-VL-7B-INSTRUCT (4-bit Quantized)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Use Qwen2.5-VL-7B model (publicly available)\n",
    "    model_name = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "    \n",
    "    print(f\"\\nLoading model: {model_name}\")\n",
    "    print(\"This may take 3-5 minutes with quantization...\")\n",
    "    \n",
    "    # 4-bit quantization config for memory efficiency\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "    \n",
    "    # Load processor\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(\"Processor loaded!\")\n",
    "    \n",
    "    # Load model with 4-bit quantization\n",
    "    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    print(\"Model loaded with 4-bit quantization!\")\n",
    "    \n",
    "    # Print memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        print(f\"GPU Memory Used: {allocated:.2f} GB\")\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "\n",
    "def unload_model(model, processor):\n",
    "    \"\"\"Unload model to free GPU memory.\"\"\"\n",
    "    print(\"\\nUnloading model...\")\n",
    "    del model\n",
    "    del processor\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Model unloaded and memory cleared!\")\n",
    "\n",
    "print(\"Model loading functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ed313",
   "metadata": {},
   "source": [
    "### Prediction Function\n",
    "Define single image prediction with OOM handling and label extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1cf32d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:02.377121Z",
     "iopub.status.busy": "2025-12-05T09:27:02.376840Z",
     "iopub.status.idle": "2025-12-05T09:27:02.396333Z",
     "shell.execute_reply": "2025-12-05T09:27:02.395673Z",
     "shell.execute_reply.started": "2025-12-05T09:27:02.377097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Define Prediction Function\n",
    "\n",
    "def predict_single_image(model, processor, image_path, prompt, max_retries=2):\n",
    "    \"\"\"\n",
    "    Predict classification for a single image with error handling.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Load and resize image (reduce memory)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            # Resize if too large\n",
    "            max_size = 512\n",
    "            if max(image.size) > max_size:\n",
    "                ratio = max_size / max(image.size)\n",
    "                new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))\n",
    "                image = image.resize(new_size, Image.LANCZOS)\n",
    "            \n",
    "            # Prepare messages in Qwen format\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \"image\": image},\n",
    "                        {\"type\": \"text\", \"text\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # Apply chat template\n",
    "            text = processor.apply_chat_template(\n",
    "                messages, \n",
    "                tokenize=False, \n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            \n",
    "            # Process inputs\n",
    "            inputs = processor(\n",
    "                text=[text],\n",
    "                images=[image],\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "            \n",
    "            # Generate response (short for efficiency)\n",
    "            with torch.no_grad():\n",
    "                generated_ids = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=256,\n",
    "                    do_sample=False,\n",
    "                    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                )\n",
    "            \n",
    "            # Decode response\n",
    "            generated_ids_trimmed = [\n",
    "                out_ids[len(in_ids):] \n",
    "                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "            response = processor.batch_decode(\n",
    "                generated_ids_trimmed, \n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "            \n",
    "            # Extract final answer\n",
    "            label = extract_label(response)\n",
    "            \n",
    "            # Clear intermediate tensors\n",
    "            del inputs, generated_ids, generated_ids_trimmed\n",
    "            \n",
    "            return {\n",
    "                'reasoning': response,\n",
    "                'label': label,\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"   OOM error, clearing cache (attempt {attempt+1})...\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            if attempt == max_retries - 1:\n",
    "                return {'reasoning': '', 'label': '', 'status': 'oom'}\n",
    "        except Exception as e:\n",
    "            print(f\"   Error: {str(e)[:50]}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return {'reasoning': '', 'label': '', 'status': 'failed'}\n",
    "    \n",
    "    return {'reasoning': '', 'label': '', 'status': 'failed'}\n",
    "\n",
    "def extract_label(response):\n",
    "    \"\"\"\n",
    "    Extract the final classification label from the model response.\n",
    "    \"\"\"\n",
    "    response_upper = response.upper()\n",
    "    \n",
    "    # Look for explicit FINAL_ANSWER pattern\n",
    "    if 'FINAL_ANSWER:' in response_upper:\n",
    "        match = re.search(r'FINAL_ANSWER:\\s*(POLITICAL|NONPOLITICAL|NON-POLITICAL)', response_upper)\n",
    "        if match:\n",
    "            label = match.group(1)\n",
    "            return 'NonPolitical' if 'NON' in label else 'Political'\n",
    "    \n",
    "    # Fallback: Look for keywords in the last part of response\n",
    "    last_part = response_upper[-300:]\n",
    "    \n",
    "    if 'NONPOLITICAL' in last_part or 'NON-POLITICAL' in last_part or 'NON POLITICAL' in last_part:\n",
    "        return 'NonPolitical'\n",
    "    elif 'POLITICAL' in last_part:\n",
    "        return 'Political'\n",
    "    \n",
    "    # Last resort: empty (will be filled by fallback)\n",
    "    return ''\n",
    "\n",
    "print(\"Prediction functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61cc0e",
   "metadata": {},
   "source": [
    "### Stage 1 Pipeline\n",
    "Main prediction loop with checkpointing (saves every 10 images) and detailed reasoning output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f499c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:02.397573Z",
     "iopub.status.busy": "2025-12-05T09:27:02.397083Z",
     "iopub.status.idle": "2025-12-05T09:27:02.418239Z",
     "shell.execute_reply": "2025-12-05T09:27:02.417562Z",
     "shell.execute_reply.started": "2025-12-05T09:27:02.397547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction pipeline defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Main Prediction Pipeline\n",
    "\n",
    "def run_prediction_pipeline(df, image_dir, checkpoint_path, batch_save=10):\n",
    "    \"\"\"\n",
    "    Run predictions on all images with checkpointing.\n",
    "    Optimized for free-tier GPU with frequent saves.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING STAGE 1: INITIAL CLASSIFICATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load model\n",
    "    model, processor = load_qwen_model()\n",
    "    \n",
    "    # Prepare results DataFrame\n",
    "    results_df = df.copy()\n",
    "    if 'Predicted_Label' not in results_df.columns:\n",
    "        results_df['Predicted_Label'] = ''\n",
    "    if 'Reasoning' not in results_df.columns:\n",
    "        results_df['Reasoning'] = ''\n",
    "    \n",
    "    # Check for existing checkpoint\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"\\nLoading checkpoint...\")\n",
    "        try:\n",
    "            checkpoint_df = pd.read_csv(checkpoint_path)\n",
    "            # Merge predictions\n",
    "            for idx, row in checkpoint_df.iterrows():\n",
    "                pred = row.get('Predicted_Label', '')\n",
    "                if pd.notna(pred) and pred != '':\n",
    "                    match_idx = results_df[results_df['Image_name'] == row['Image_name']].index\n",
    "                    if len(match_idx) > 0:\n",
    "                        results_df.loc[match_idx[0], 'Predicted_Label'] = pred\n",
    "                        results_df.loc[match_idx[0], 'Reasoning'] = row.get('Reasoning', '')\n",
    "            print(f\"   Loaded checkpoint with existing predictions\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Could not load checkpoint: {e}\")\n",
    "    \n",
    "    # Find images to process\n",
    "    to_process = results_df[\n",
    "        (results_df['Predicted_Label'].isna()) | (results_df['Predicted_Label'] == '')\n",
    "    ].index.tolist()\n",
    "    total = len(to_process)\n",
    "    \n",
    "    print(f\"\\nStatus:\")\n",
    "    print(f\"   Total images: {len(results_df)}\")\n",
    "    print(f\"   Already done: {len(results_df) - total}\")\n",
    "    print(f\"   To process: {total}\")\n",
    "    \n",
    "    if total == 0:\n",
    "        print(\"\\nAll images already processed!\")\n",
    "        unload_model(model, processor)\n",
    "        return results_df\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"PROCESSING LOG\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    success_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    for i, idx in enumerate(to_process):\n",
    "        row = results_df.loc[idx]\n",
    "        image_name = row['Image_name']\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        \n",
    "        # Progress\n",
    "        print(f\"\\n[{i+1}/{total}] {image_name}\")\n",
    "        \n",
    "        # Check image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"   Image not found!\")\n",
    "            failed_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = create_cot_prompt(row)\n",
    "        \n",
    "        # Predict\n",
    "        print(f\"   Analyzing...\")\n",
    "        result = predict_single_image(model, processor, image_path, prompt)\n",
    "        \n",
    "        if result['status'] == 'success' and result['label']:\n",
    "            results_df.loc[idx, 'Predicted_Label'] = result['label']\n",
    "            results_df.loc[idx, 'Reasoning'] = str(result['reasoning'])[:500]\n",
    "            print(f\"   Predicted: {result['label']}\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"   Failed or empty prediction\")\n",
    "            failed_count += 1\n",
    "        \n",
    "        # Save checkpoint frequently\n",
    "        if (i + 1) % batch_save == 0:\n",
    "            print(f\"\\n   Saving checkpoint ({i+1}/{total} done)...\")\n",
    "            results_df.to_csv(checkpoint_path, index=False)\n",
    "        \n",
    "        # Clear cache every 20 images\n",
    "        if (i + 1) % 20 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    # Final save\n",
    "    results_df.to_csv(checkpoint_path, index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STAGE 1 COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   Successful: {success_count}\")\n",
    "    print(f\"   Failed: {failed_count}\")\n",
    "    \n",
    "    # Unload model\n",
    "    unload_model(model, processor)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"Prediction pipeline defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa368e9d",
   "metadata": {},
   "source": [
    "### Run Stage 1\n",
    "Execute Stage 1 classification on all images (~30-60 min on T4 GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbab8056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:02.419194Z",
     "iopub.status.busy": "2025-12-05T09:27:02.418943Z",
     "iopub.status.idle": "2025-12-05T10:08:19.913594Z",
     "shell.execute_reply": "2025-12-05T10:08:19.912839Z",
     "shell.execute_reply.started": "2025-12-05T09:27:02.419171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Stage 1: Initial Predictions\n",
      "This will take some time...\n",
      "\n",
      "======================================================================\n",
      "STARTING STAGE 1: INITIAL CLASSIFICATION\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "LOADING QWEN2.5-VL-7B-INSTRUCT (4-bit Quantized)\n",
      "============================================================\n",
      "\n",
      "Loading model: Qwen/Qwen2.5-VL-7B-Instruct\n",
      "This may take 3-5 minutes with quantization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fb144da89844efaef69fe17ea3ed77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb165339fffd4dae85bd9ee8887c4a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b680199c37e439eaf3f49eed69f2ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e64f645a5d94e0a80fd4b598aaed918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb37bf376a74ed5a06c9956a3e7e5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96c58f582b946ca8dfe4e98923539c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a298fb0f3a4f2e88d1b73dabb877cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d881332e01c84814a3c2bb2223f78ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938dbd91031246ef9981fad60d959996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad131f938b8d406ca86cb06499190240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b4fc441b184cf299a33fbfba221e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f83d32ba41745429371b0d95c5082a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e87149ecc9443ac8758b76b58b98312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb75d8cd22a3485db14c431bdb95fbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61730669fe1c4318ae23080080a4d3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4470433ace4856a72923ce9ca45aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/216 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with 4-bit quantization!\n",
      "GPU Memory Used: 5.94 GB\n",
      "\n",
      "Status:\n",
      "   Total images: 330\n",
      "   Already done: 0\n",
      "   To process: 330\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PROCESSING LOG\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[1/330] test0001.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[2/330] test0002.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[3/330] test0003.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[4/330] test0004.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[5/330] test0005.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[6/330] test0006.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[7/330] test0007.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[8/330] test0008.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[9/330] test0009.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[10/330] test0010.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (10/330 done)...\n",
      "\n",
      "[11/330] test0011.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[12/330] test0012.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[13/330] test0013.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[14/330] test0014.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[15/330] test0015.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[16/330] test0016.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[17/330] test0017.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[18/330] test0018.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[19/330] test0019.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[20/330] test0020.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (20/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[21/330] test0021.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[22/330] test0022.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[23/330] test0023.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[24/330] test0024.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[25/330] test0025.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[26/330] test0026.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[27/330] test0027.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[28/330] test0028.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[29/330] test0029.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[30/330] test0030.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (30/330 done)...\n",
      "\n",
      "[31/330] test0031.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[32/330] test0032.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[33/330] test0033.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[34/330] test0034.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[35/330] test0035.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[36/330] test0036.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[37/330] test0037.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[38/330] test0038.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[39/330] test0039.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[40/330] test0040.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (40/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[41/330] test0041.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[42/330] test0042.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[43/330] test0043.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[44/330] test0044.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[45/330] test0045.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[46/330] test0046.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[47/330] test0047.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[48/330] test0048.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[49/330] test0049.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[50/330] test0050.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (50/330 done)...\n",
      "\n",
      "[51/330] test0051.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[52/330] test0052.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[53/330] test0053.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[54/330] test0054.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[55/330] test0055.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[56/330] test0056.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[57/330] test0057.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[58/330] test0058.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[59/330] test0059.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[60/330] test0060.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (60/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[61/330] test0061.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[62/330] test0062.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[63/330] test0063.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[64/330] test0064.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[65/330] test0065.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[66/330] test0066.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[67/330] test0067.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[68/330] test0068.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[69/330] test0069.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[70/330] test0070.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (70/330 done)...\n",
      "\n",
      "[71/330] test0071.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[72/330] test0072.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[73/330] test0073.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[74/330] test0074.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[75/330] test0075.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[76/330] test0076.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[77/330] test0077.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[78/330] test0078.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[79/330] test0079.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[80/330] test0080.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (80/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[81/330] test0081.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[82/330] test0082.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[83/330] test0083.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[84/330] test0084.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[85/330] test0085.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[86/330] test0086.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[87/330] test0087.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[88/330] test0088.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[89/330] test0089.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[90/330] test0090.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (90/330 done)...\n",
      "\n",
      "[91/330] test0091.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[92/330] test0092.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[93/330] test0093.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[94/330] test0094.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[95/330] test0095.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[96/330] test0096.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[97/330] test0097.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[98/330] test0098.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[99/330] test0099.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[100/330] test0100.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (100/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[101/330] test0101.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[102/330] test0102.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[103/330] test0103.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[104/330] test0104.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[105/330] test0105.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[106/330] test0106.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[107/330] test0107.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[108/330] test0108.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[109/330] test0109.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[110/330] test0110.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (110/330 done)...\n",
      "\n",
      "[111/330] test0111.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[112/330] test0112.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[113/330] test0113.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[114/330] test0114.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[115/330] test0115.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[116/330] test0116.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[117/330] test0117.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[118/330] test0118.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[119/330] test0119.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[120/330] test0120.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (120/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[121/330] test0121.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[122/330] test0122.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[123/330] test0123.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[124/330] test0124.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[125/330] test0125.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[126/330] test0126.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[127/330] test0127.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[128/330] test0128.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[129/330] test0129.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[130/330] test0130.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (130/330 done)...\n",
      "\n",
      "[131/330] test0131.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[132/330] test0132.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[133/330] test0133.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[134/330] test0134.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[135/330] test0135.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[136/330] test0136.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[137/330] test0137.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[138/330] test0138.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[139/330] test0139.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[140/330] test0140.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (140/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[141/330] test0141.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[142/330] test0142.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[143/330] test0143.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[144/330] test0144.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[145/330] test0145.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[146/330] test0146.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[147/330] test0147.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[148/330] test0148.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[149/330] test0149.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[150/330] test0150.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (150/330 done)...\n",
      "\n",
      "[151/330] test0151.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[152/330] test0152.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[153/330] test0153.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[154/330] test0154.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[155/330] test0155.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[156/330] test0156.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[157/330] test0157.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[158/330] test0158.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[159/330] test0159.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[160/330] test0160.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (160/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[161/330] test0161.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[162/330] test0162.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[163/330] test0163.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[164/330] test0164.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[165/330] test0165.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[166/330] test0166.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[167/330] test0167.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[168/330] test0168.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[169/330] test0169.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[170/330] test0170.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (170/330 done)...\n",
      "\n",
      "[171/330] test0171.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[172/330] test0172.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[173/330] test0173.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[174/330] test0174.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[175/330] test0175.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[176/330] test0176.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[177/330] test0177.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[178/330] test0178.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[179/330] test0179.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[180/330] test0180.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (180/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[181/330] test0181.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[182/330] test0182.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[183/330] test0183.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[184/330] test0184.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[185/330] test0185.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[186/330] test0186.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[187/330] test0187.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[188/330] test0188.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[189/330] test0189.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "[190/330] test0190.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (190/330 done)...\n",
      "\n",
      "[191/330] test0191.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[192/330] test0192.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[193/330] test0193.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[194/330] test0194.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[195/330] test0195.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[196/330] test0196.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[197/330] test0197.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[198/330] test0198.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[199/330] test0199.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[200/330] test0200.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (200/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[201/330] test0201.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[202/330] test0202.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[203/330] test0203.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[204/330] test0204.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[205/330] test0205.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[206/330] test0206.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[207/330] test0207.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[208/330] test0208.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[209/330] test0209.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[210/330] test0210.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (210/330 done)...\n",
      "\n",
      "[211/330] test0211.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[212/330] test0212.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[213/330] test0213.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[214/330] test0214.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[215/330] test0215.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[216/330] test0216.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[217/330] test0217.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[218/330] test0218.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[219/330] test0219.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[220/330] test0220.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (220/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[221/330] test0221.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[222/330] test0222.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[223/330] test0223.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[224/330] test0224.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[225/330] test0225.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[226/330] test0226.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[227/330] test0227.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[228/330] test0228.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[229/330] test0229.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[230/330] test0230.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (230/330 done)...\n",
      "\n",
      "[231/330] test0231.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[232/330] test0232.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[233/330] test0233.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[234/330] test0234.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[235/330] test0235.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[236/330] test0236.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[237/330] test0237.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[238/330] test0238.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[239/330] test0239.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[240/330] test0240.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (240/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[241/330] test0241.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[242/330] test0242.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[243/330] test0243.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[244/330] test0244.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[245/330] test0245.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[246/330] test0246.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[247/330] test0247.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[248/330] test0248.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[249/330] test0249.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[250/330] test0250.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (250/330 done)...\n",
      "\n",
      "[251/330] test0251.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[252/330] test0252.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[253/330] test0253.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[254/330] test0254.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[255/330] test0255.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[256/330] test0256.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[257/330] test0257.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[258/330] test0258.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[259/330] test0259.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[260/330] test0260.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (260/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[261/330] test0261.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[262/330] test0262.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[263/330] test0263.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[264/330] test0264.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[265/330] test0265.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[266/330] test0266.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[267/330] test0267.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[268/330] test0268.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[269/330] test0269.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[270/330] test0270.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (270/330 done)...\n",
      "\n",
      "[271/330] test0271.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[272/330] test0272.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[273/330] test0273.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[274/330] test0274.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[275/330] test0275.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[276/330] test0276.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[277/330] test0277.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[278/330] test0278.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[279/330] test0279.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[280/330] test0280.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (280/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[281/330] test0281.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[282/330] test0282.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[283/330] test0283.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[284/330] test0284.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[285/330] test0285.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[286/330] test0286.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[287/330] test0287.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[288/330] test0288.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[289/330] test0289.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[290/330] test0290.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (290/330 done)...\n",
      "\n",
      "[291/330] test0291.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[292/330] test0292.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[293/330] test0293.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[294/330] test0294.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[295/330] test0295.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[296/330] test0296.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[297/330] test0297.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[298/330] test0298.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[299/330] test0299.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[300/330] test0300.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (300/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[301/330] test0301.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[302/330] test0302.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[303/330] test0303.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[304/330] test0304.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[305/330] test0305.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[306/330] test0306.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[307/330] test0307.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[308/330] test0308.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[309/330] test0309.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[310/330] test0310.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (310/330 done)...\n",
      "\n",
      "[311/330] test0311.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[312/330] test0312.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[313/330] test0313.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[314/330] test0314.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[315/330] test0315.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[316/330] test0316.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[317/330] test0317.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[318/330] test0318.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[319/330] test0319.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[320/330] test0320.jpg\n",
      "   Analyzing...\n",
      "   Predicted: Political\n",
      "\n",
      "   Saving checkpoint (320/330 done)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[321/330] test0321.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[322/330] test0322.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[323/330] test0323.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[324/330] test0324.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[325/330] test0325.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[326/330] test0326.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[327/330] test0327.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[328/330] test0328.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: NonPolitical\n",
      "\n",
      "[329/330] test0329.jpg\n",
      "   Analyzing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted: Political\n",
      "\n",
      "[330/330] test0330.jpg\n",
      "   Analyzing...\n",
      "   Predicted: NonPolitical\n",
      "\n",
      "   Saving checkpoint (330/330 done)...\n",
      "\n",
      "======================================================================\n",
      "STAGE 1 COMPLETE!\n",
      "======================================================================\n",
      "   Successful: 330\n",
      "   Failed: 0\n",
      "\n",
      "Unloading model...\n",
      "Model unloaded and memory cleared!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run Stage 1 Prediction Pipeline\n",
    "# This cell processes all images. Takes ~30-60 minutes on T4 GPU.\n",
    "\n",
    "print(\"Starting Stage 1: Initial Predictions\")\n",
    "print(\"This will take some time...\")\n",
    "\n",
    "results_df = run_prediction_pipeline(\n",
    "    df=df,\n",
    "    image_dir=IMAGE_DIR,\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    batch_save=10  # Save every 10 images for safety\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f72c1",
   "metadata": {},
   "source": [
    "### Stage 1 Status\n",
    "Check prediction progress, label distribution, and save Stage 1 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b5eedd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:08:19.916019Z",
     "iopub.status.busy": "2025-12-05T10:08:19.915734Z",
     "iopub.status.idle": "2025-12-05T10:08:19.941482Z",
     "shell.execute_reply": "2025-12-05T10:08:19.940936Z",
     "shell.execute_reply.started": "2025-12-05T10:08:19.916000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 1 PREDICTION STATUS\n",
      "============================================================\n",
      "\n",
      "Progress:\n",
      "   Total: 330\n",
      "   Predicted: 330 (100.0%)\n",
      "   Empty: 0\n",
      "\n",
      "Label Distribution:\n",
      "   NonPolitical: 174 (52.7%)\n",
      "   Political: 156 (47.3%)\n",
      "\n",
      "✓ Stage 1 predictions saved to: /kaggle/working/stage1_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Check Stage 1 Prediction Status and Save\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STAGE 1 PREDICTION STATUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total = len(results_df)\n",
    "filled = results_df['Predicted_Label'].notna() & (results_df['Predicted_Label'] != '')\n",
    "filled_count = filled.sum()\n",
    "empty_count = total - filled_count\n",
    "\n",
    "print(f\"\\nProgress:\")\n",
    "print(f\"   Total: {total}\")\n",
    "print(f\"   Predicted: {filled_count} ({filled_count/total*100:.1f}%)\")\n",
    "print(f\"   Empty: {empty_count}\")\n",
    "\n",
    "if filled_count > 0:\n",
    "    print(f\"\\nLabel Distribution:\")\n",
    "    label_counts = results_df[filled]['Predicted_Label'].value_counts()\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"   {label}: {count} ({count/filled_count*100:.1f}%)\")\n",
    "\n",
    "# Show empty ones\n",
    "if empty_count > 0:\n",
    "    print(f\"\\nEmpty predictions ({empty_count}):\")\n",
    "    empty_rows = results_df[~filled]['Image_name'].tolist()\n",
    "    for img in empty_rows[:10]:\n",
    "        print(f\"   {img}\")\n",
    "    if len(empty_rows) > 10:\n",
    "        print(f\"   ... and {len(empty_rows)-10} more\")\n",
    "\n",
    "# Save Stage 1 predictions\n",
    "STAGE1_OUTPUT_PATH = f\"{OUTPUT_DIR}/stage1_prediction.csv\"\n",
    "results_df.to_csv(STAGE1_OUTPUT_PATH, index=False)\n",
    "print(f\"\\n✓ Stage 1 predictions saved to: {STAGE1_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981174b",
   "metadata": {},
   "source": [
    "---\n",
    "# STAGE 2: Keyword-Based Validation (Phi-3-Vision)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b3fac9",
   "metadata": {},
   "source": [
    "### Load Phi-3-Vision Model\n",
    "Load Microsoft Phi-3-Vision-128k-Instruct for Stage 2 visual validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "287aac7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:08:19.942436Z",
     "iopub.status.busy": "2025-12-05T10:08:19.942170Z",
     "iopub.status.idle": "2025-12-05T10:08:19.948176Z",
     "shell.execute_reply": "2025-12-05T10:08:19.947473Z",
     "shell.execute_reply.started": "2025-12-05T10:08:19.942413Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi-3-Vision Stage 2 model loading function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Load Phi-3-Vision Model for Stage 2 Validation\n",
    "\n",
    "def load_phi3_vision_model():\n",
    "    \"\"\"\n",
    "    Load Microsoft Phi-3-Vision-128k-Instruct for Stage 2 keyword-based validation.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LOADING PHI-3-VISION-128K-INSTRUCT FOR STAGE 2 VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "    \n",
    "    model_name = \"microsoft/Phi-3-vision-128k-instruct\"\n",
    "    \n",
    "    print(f\"\\nLoading model: {model_name}\")\n",
    "    print(\"This may take 3-5 minutes...\")\n",
    "    \n",
    "    # Load processor\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(\"Processor loaded!\")\n",
    "    \n",
    "    # Load model with float16 for T4 GPU\n",
    "    # _attn_implementation='eager' is CRITICAL for T4 compatibility\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        _attn_implementation=\"eager\"\n",
    "    )\n",
    "    print(\"Model loaded!\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        print(f\"GPU Memory Used: {allocated:.2f} GB\")\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "print(\"Phi-3-Vision Stage 2 model loading function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c571a0ed",
   "metadata": {},
   "source": [
    "### Political Keywords and Validation Prompt\n",
    "Define political/non-political keywords and Stage 2 validation prompt with knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc14b36f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:08:19.949198Z",
     "iopub.status.busy": "2025-12-05T10:08:19.948931Z",
     "iopub.status.idle": "2025-12-05T10:08:19.970330Z",
     "shell.execute_reply": "2025-12-05T10:08:19.969755Z",
     "shell.execute_reply.started": "2025-12-05T10:08:19.949183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 keywords and prompt defined!\n",
      "Political keywords: 60\n",
      "Non-political keywords: 3\n",
      "\n",
      "Sample extracted_text and Language from CSV:\n",
      "   test0001.jpg: Lang=English, Text=*Looses Ducsu Election\n",
      "- Any comment on the election?\n",
      "- I'm a bid disappointed, ...\n",
      "   test0002.jpg: Lang=Banglish, Text=kya matlab ke fue...\n",
      "   test0003.jpg: Lang=Banglish, Text=SNACKS MUJIB DURING\n",
      "15TH AUG SEHR!...\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Define Stage 2 Keywords and Simple Validation Prompt\n",
    "\n",
    "# Keywords to improve Stage 1 predictions\n",
    "POLITICAL_KEYWORDS = [\n",
    "    # Specific terms\n",
    "    'zohran', 'jahoran', 'জোহরান', \n",
    "    'bimpi', 'বিম্পি',\n",
    "    'পদপ্রার্থী',  # Candidate/Nominee\n",
    "    'aamjonota', 'Aamjonota', 'আমজনতা',  # Including Bangla\n",
    "    'ncp', 'NCP', 'National Citizen Party',\n",
    "    'জাতীয়তাবাদী ছাত্র',  # Nationalist student\n",
    "    \n",
    "    # Politicians\n",
    "    'sheikh hasina', 'hasina', 'শেখ হাসিনা', 'হাসিনা',\n",
    "    'khaleda zia', 'khaleda', 'খালেদা জিয়া', 'খালেদা',\n",
    "    'tarek zia', 'tarique rahman', 'তারেক জিয়া', 'তারেক রহমান',\n",
    "    'ershad', 'এরশাদ',\n",
    "    'bangabandhu', 'বঙ্গবন্ধু', 'mujib', 'মুজিব',\n",
    "    'zia', 'জিয়া', 'ziaur rahman', 'জিয়াউর রহমান',\n",
    "    \n",
    "    # Political parties & logos\n",
    "    'awami league', 'আওয়ামী লীগ', 'awami', 'আওয়ামী',\n",
    "    'bnp', 'বিএনপি', 'bangladesh nationalist party',\n",
    "    'jatiya party', 'জাতীয় পার্টি',\n",
    "    'jamaat', 'জামায়াত', 'shibir', 'শিবির',\n",
    "    'bcl', 'ছাত্রলীগ', 'chhatra league',\n",
    "    'chhatra dal', 'ছাত্রদল',\n",
    "    \n",
    "    # Political symbols/logos\n",
    "    'boat logo', 'নৌকা', 'nouka',  # Awami League symbol\n",
    "    'sheaf of paddy', 'ধানের শীষ',  # BNP symbol\n",
    "    'plough', 'লাঙ্গল'  # Jatiya Party symbol\n",
    "]\n",
    "\n",
    "# Non-political keywords - if found, keep as NonPolitical\n",
    "NON_POLITICAL_KEYWORDS = [\n",
    "    'bkash', 'বিকাশ', 'bKash'\n",
    "]\n",
    "\n",
    "def check_keywords_in_text(text, keywords):\n",
    "    \"\"\"Check if any keyword is present in the text.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False, []\n",
    "    \n",
    "    text_lower = str(text).lower()\n",
    "    found = [k for k in keywords if k.lower() in text_lower]\n",
    "    return len(found) > 0, found\n",
    "\n",
    "def check_non_political_keywords(text):\n",
    "    \"\"\"Check if non-political keywords are present.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False, []\n",
    "    \n",
    "    text_lower = str(text).lower()\n",
    "    found = [k for k in NON_POLITICAL_KEYWORDS if k.lower() in text_lower]\n",
    "    return len(found) > 0, found\n",
    "\n",
    "def create_stage2_validation_prompt(row, previous_label):\n",
    "    \"\"\"Simple prompt using extracted_text and Language for validation.\"\"\"\n",
    "    \n",
    "    # Get extracted text and language from the row\n",
    "    extracted_text = row.get('extracted_text', '')\n",
    "    if pd.isna(extracted_text):\n",
    "        extracted_text = 'No text found'\n",
    "    \n",
    "    language = row.get('Language', '')\n",
    "    if pd.isna(language):\n",
    "        language = 'Unknown'\n",
    "    \n",
    "    prompt = f\"\"\"Look at this meme image carefully.\n",
    "\n",
    "Current label: {previous_label}\n",
    "\n",
    "EXTRACTED TEXT FROM MEME:\n",
    "\"{extracted_text}\"\n",
    "\n",
    "LANGUAGE: {language}\n",
    "\n",
    "Check if you see ANY of these in the IMAGE or TEXT:\n",
    "\n",
    "POLITICIANS:\n",
    "- Sheikh Hasina, Khaleda Zia, Tarek Zia, Ershad, Bangabandhu/Mujib\n",
    "\n",
    "POLITICAL PARTIES/LOGOS:\n",
    "- Awami League (boat/নৌকা logo)\n",
    "- BNP (sheaf of paddy/ধানের শীষ logo)\n",
    "- Jamaat, Shibir, BCL, Chhatra Dal\n",
    "- NCP, National Citizen Party, Aamjonota/আমজনতা\n",
    "\n",
    "SPECIFIC KEYWORDS:\n",
    "- zohran/jahoran (জোহরান), bimpi (বিম্পি)\n",
    "- পদপ্রার্থী (candidate), জাতীয়তাবাদী ছাত্র (nationalist student)\n",
    "\n",
    "NON-POLITICAL (keep as NonPolitical if found):\n",
    "- bKash/বিকাশ (mobile banking)\n",
    "\n",
    "If you find ANY politician, party logo, or political keyword in image OR extracted text → answer Political.\n",
    "If you find bKash/বিকাশ → answer NonPolitical.\n",
    "If you don't find any political content → keep current label.\n",
    "\n",
    "FINAL_ANSWER: [Political or NonPolitical]\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def predict_with_phi3(model, processor, image_path, prompt, max_retries=2):\n",
    "    \"\"\"\n",
    "    Predict using Phi-3-Vision model.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Load and resize image\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            max_size = 512\n",
    "            if max(image.size) > max_size:\n",
    "                ratio = max_size / max(image.size)\n",
    "                new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))\n",
    "                image = image.resize(new_size, Image.LANCZOS)\n",
    "            \n",
    "            # Phi-3-Vision format with <|image_1|> placeholder\n",
    "            user_prompt = f\"<|image_1|>\\n{prompt}\"\n",
    "            \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            \n",
    "            # Apply chat template\n",
    "            text = processor.tokenizer.apply_chat_template(\n",
    "                messages, \n",
    "                tokenize=False, \n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            \n",
    "            # Process inputs\n",
    "            inputs = processor(text, [image], return_tensors=\"pt\").to(model.device)\n",
    "            \n",
    "            # Generate\n",
    "            with torch.no_grad():\n",
    "                generate_ids = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=200,\n",
    "                    do_sample=False,\n",
    "                    temperature=0.0\n",
    "                )\n",
    "            \n",
    "            # Decode\n",
    "            generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "            response = processor.batch_decode(\n",
    "                generate_ids, \n",
    "                skip_special_tokens=True, \n",
    "                clean_up_tokenization_spaces=False\n",
    "            )[0]\n",
    "            \n",
    "            # Extract label\n",
    "            label = extract_label(response)\n",
    "            \n",
    "            # Clear tensors\n",
    "            del inputs, generate_ids\n",
    "            \n",
    "            return {\n",
    "                'reasoning': response,\n",
    "                'label': label,\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"   OOM error, clearing cache (attempt {attempt+1})...\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            if attempt == max_retries - 1:\n",
    "                return {'reasoning': '', 'label': '', 'status': 'oom'}\n",
    "        except Exception as e:\n",
    "            print(f\"   Error: {str(e)[:50]}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return {'reasoning': '', 'label': '', 'status': 'failed'}\n",
    "    \n",
    "    return {'reasoning': '', 'label': '', 'status': 'failed'}\n",
    "\n",
    "print(\"Stage 2 keywords and prompt defined!\")\n",
    "print(f\"Political keywords: {len(POLITICAL_KEYWORDS)}\")\n",
    "print(f\"Non-political keywords: {len(NON_POLITICAL_KEYWORDS)}\")\n",
    "\n",
    "# Show sample of extracted_text and Language columns\n",
    "print(\"\\nSample extracted_text and Language from CSV:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    row = df.iloc[i]\n",
    "    text = str(row.get('extracted_text', ''))[:80] if pd.notna(row.get('extracted_text')) else 'N/A'\n",
    "    lang = row.get('Language', 'N/A')\n",
    "    print(f\"   {row['Image_name']}: Lang={lang}, Text={text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ef2bc",
   "metadata": {},
   "source": [
    "### Stage 2 Validation Pipeline\n",
    "Two-phase validation: text-based keyword matching + visual validation with Phi-3-Vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0560806c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:08:19.972859Z",
     "iopub.status.busy": "2025-12-05T10:08:19.972595Z",
     "iopub.status.idle": "2025-12-05T10:08:19.992561Z",
     "shell.execute_reply": "2025-12-05T10:08:19.991892Z",
     "shell.execute_reply.started": "2025-12-05T10:08:19.972843Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 validation pipeline defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Run Stage 2 Keyword-Based Validation\n",
    "\n",
    "def run_stage2_validation(results_df, image_dir, stage2_checkpoint_path):\n",
    "    \"\"\"\n",
    "    Stage 2: Validate predictions using Phi-3-Vision with keyword focus.\n",
    "    Only changes NonPolitical to Political if keywords/figures found.\n",
    "    Also checks for non-political keywords to prevent false positives.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING STAGE 2: KEYWORD-BASED VALIDATION (PHI-3-VISION)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # First, do text-based keyword check (fast)\n",
    "    print(\"\\n[Phase 1] Text-based keyword detection...\")\n",
    "    keyword_matches = 0\n",
    "    non_political_matches = 0\n",
    "    \n",
    "    for idx, row in results_df.iterrows():\n",
    "        # Check all text columns\n",
    "        all_text = ' '.join([\n",
    "            str(row.get('extracted_text', '')),\n",
    "            str(row.get('Language', '')),\n",
    "            str(row.get('Meme_Explanation', '')),\n",
    "            str(row.get('Metaphor_Object', '')),\n",
    "            str(row.get('Humor', ''))\n",
    "        ])\n",
    "        \n",
    "        # First check for non-political keywords (bkash, etc.)\n",
    "        has_non_political, non_pol_found = check_non_political_keywords(all_text)\n",
    "        \n",
    "        if has_non_political and row['Predicted_Label'] == 'Political':\n",
    "            # If bkash found and currently Political, change to NonPolitical\n",
    "            results_df.loc[idx, 'Predicted_Label'] = 'NonPolitical'\n",
    "            results_df.loc[idx, 'Reasoning'] = f'Stage2 non-political keyword: {non_pol_found[:3]}'\n",
    "            non_political_matches += 1\n",
    "            print(f\"   {row['Image_name']}: Political -> NonPolitical (keywords: {non_pol_found[:3]})\")\n",
    "        elif row['Predicted_Label'] == 'NonPolitical' and not has_non_political:\n",
    "            # Check for political keywords only if no non-political keywords found\n",
    "            has_keywords, found = check_keywords_in_text(all_text, POLITICAL_KEYWORDS)\n",
    "            \n",
    "            if has_keywords:\n",
    "                results_df.loc[idx, 'Predicted_Label'] = 'Political'\n",
    "                results_df.loc[idx, 'Reasoning'] = f'Stage2 keyword match: {found[:3]}'\n",
    "                keyword_matches += 1\n",
    "                print(f\"   {row['Image_name']}: NonPolitical -> Political (keywords: {found[:3]})\")\n",
    "    \n",
    "    print(f\"\\nPhase 1 complete:\")\n",
    "    print(f\"   NonPolitical -> Political: {keyword_matches}\")\n",
    "    print(f\"   Political -> NonPolitical: {non_political_matches}\")\n",
    "    \n",
    "    # Load Phi-3-Vision model for visual validation\n",
    "    print(\"\\n[Phase 2] Loading Phi-3-Vision for visual validation...\")\n",
    "    model, processor = load_phi3_vision_model()\n",
    "    \n",
    "    # Only validate NonPolitical predictions with model (to catch visual political content)\n",
    "    to_validate = results_df[results_df['Predicted_Label'] == 'NonPolitical'].index.tolist()\n",
    "    \n",
    "    print(f\"\\nImages to validate with model: {len(to_validate)}\")\n",
    "    \n",
    "    changes_count = 0\n",
    "    \n",
    "    for i, idx in enumerate(to_validate):\n",
    "        row = results_df.loc[idx]\n",
    "        image_name = row['Image_name']\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        previous_label = row['Predicted_Label']\n",
    "        \n",
    "        print(f\"\\n[{i+1}/{len(to_validate)}] {image_name}\")\n",
    "        print(f\"   Current: {previous_label}\")\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"   Image not found!\")\n",
    "            continue\n",
    "        \n",
    "        # Skip if non-political keyword found (already confirmed as non-political)\n",
    "        all_text = ' '.join([\n",
    "            str(row.get('extracted_text', '')),\n",
    "            str(row.get('Meme_Explanation', '')),\n",
    "            str(row.get('Metaphor_Object', ''))\n",
    "        ])\n",
    "        has_non_political, _ = check_non_political_keywords(all_text)\n",
    "        if has_non_political:\n",
    "            print(f\"   Skipped: Contains non-political keyword (bkash/বিকাশ)\")\n",
    "            continue\n",
    "        \n",
    "        # Create validation prompt\n",
    "        prompt = create_stage2_validation_prompt(row, previous_label)\n",
    "        \n",
    "        # Predict with Phi-3-Vision\n",
    "        print(f\"   Validating with Phi-3-Vision...\")\n",
    "        result = predict_with_phi3(model, processor, image_path, prompt)\n",
    "        \n",
    "        if result['status'] == 'success':\n",
    "            new_label = result['label']\n",
    "            \n",
    "            # Check if political content was found\n",
    "            found_political = 'FOUND_POLITICAL_CONTENT: YES' in result['reasoning'].upper() or \\\n",
    "                            ('YES' in result['reasoning'].upper().split('FOUND_POLITICAL_CONTENT:')[1].split('\\n')[0] if 'FOUND_POLITICAL_CONTENT:' in result['reasoning'].upper() else False)\n",
    "            \n",
    "            if found_political or new_label == 'Political':\n",
    "                results_df.loc[idx, 'Predicted_Label'] = 'Political'\n",
    "                results_df.loc[idx, 'Reasoning'] = f'Stage2 visual validation: {result[\"reasoning\"][:200]}'\n",
    "                print(f\"   Changed: NonPolitical -> Political (visual content detected)\")\n",
    "                changes_count += 1\n",
    "            else:\n",
    "                print(f\"   Confirmed: NonPolitical (no political content found)\")\n",
    "        \n",
    "        # Save checkpoint every 20 images\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"\\n   Saving Stage 2 checkpoint...\")\n",
    "            results_df.to_csv(stage2_checkpoint_path, index=False)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    # Final save\n",
    "    results_df.to_csv(stage2_checkpoint_path, index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STAGE 2 VALIDATION COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   Text-based Political changes: {keyword_matches}\")\n",
    "    print(f\"   Text-based NonPolitical changes: {non_political_matches}\")\n",
    "    print(f\"   Visual validation changes: {changes_count}\")\n",
    "    print(f\"   Total changes: {keyword_matches + non_political_matches + changes_count}\")\n",
    "    \n",
    "    # Unload model\n",
    "    unload_model(model, processor)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"Stage 2 validation pipeline defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caac535",
   "metadata": {},
   "source": [
    "### Run Stage 2\n",
    "Execute Stage 2 keyword-based validation on NonPolitical predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7606c276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:08:19.993369Z",
     "iopub.status.busy": "2025-12-05T10:08:19.993155Z",
     "iopub.status.idle": "2025-12-05T10:09:36.761643Z",
     "shell.execute_reply": "2025-12-05T10:09:36.760922Z",
     "shell.execute_reply.started": "2025-12-05T10:08:19.993346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Stage 2: Keyword-Based Validation\n",
      "This will validate NonPolitical predictions for political content...\n",
      "\n",
      "\n",
      "======================================================================\n",
      "STARTING STAGE 2: KEYWORD-BASED VALIDATION (PHI-3-VISION)\n",
      "======================================================================\n",
      "\n",
      "[Phase 1] Text-based keyword detection...\n",
      "   test0100.jpg: NonPolitical -> Political (keywords: ['পদপ্রার্থী'])\n",
      "   test0104.jpg: NonPolitical -> Political (keywords: ['jahoran', 'জোহরান'])\n",
      "   test0202.jpg: NonPolitical -> Political (keywords: ['sheikh hasina', 'hasina', 'শেখ হাসিনা'])\n",
      "   test0236.jpg: NonPolitical -> Political (keywords: ['aamjonota', 'Aamjonota', 'আমজনতা'])\n",
      "   test0270.jpg: NonPolitical -> Political (keywords: ['ncp', 'NCP', 'National Citizen Party'])\n",
      "   test0302.jpg: NonPolitical -> Political (keywords: ['জামায়াত'])\n",
      "   test0320.jpg: Political -> NonPolitical (keywords: ['বিকাশ'])\n",
      "\n",
      "Phase 1 complete:\n",
      "   NonPolitical -> Political: 6\n",
      "   Political -> NonPolitical: 1\n",
      "\n",
      "[Phase 2] Loading Phi-3-Vision for visual validation...\n",
      "\n",
      "============================================================\n",
      "LOADING PHI-3-VISION-128K-INSTRUCT FOR STAGE 2 VALIDATION\n",
      "============================================================\n",
      "\n",
      "Loading model: microsoft/Phi-3-vision-128k-instruct\n",
      "This may take 3-5 minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998c2b612fe24aa58ae2cef862b9824a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/464 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2be245e92649eca38b97eb93b47771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing_phi3_v.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd20275a83714fbdb4511801b9040311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "image_processing_phi3_v.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-vision-128k-instruct:\n",
      "- image_processing_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-vision-128k-instruct:\n",
      "- processing_phi3_v.py\n",
      "- image_processing_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/image_processing_auto.py:625: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ee145d5c0b437f9e106d5bce964344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e057d058448401aa762aff708e50385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e26721fdeec47f7adbce0dfa55baa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8863c94c5b05485cbb771842294eb6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf627a25eac4d1f9ce0955ce9c7eeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3_v.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-vision-128k-instruct:\n",
      "- configuration_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e0c244ad2f47a9904f00e22dd10261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3_v.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65c553b4f84497ba6779b1db6a0af56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "image_embedding_phi3_v.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-vision-128k-instruct:\n",
      "- image_embedding_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-vision-128k-instruct:\n",
      "- modeling_phi3_v.py\n",
      "- image_embedding_phi3_v.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ddfedb6fbc4ef78ca620a34a52387b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffcb3f353f344efaffb7878f554e1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e260e7b7e1448f1be1492659f50bebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b904abefc444fcf80e133412329b592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fa78ffc8eb4f08a10a06a7fe6f5837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "GPU Memory Used: 12.06 GB\n",
      "\n",
      "Images to validate with model: 169\n",
      "\n",
      "[1/169] test0002.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[2/169] test0005.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[3/169] test0007.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[4/169] test0009.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[5/169] test0010.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[6/169] test0011.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[7/169] test0013.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[8/169] test0014.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[9/169] test0015.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[10/169] test0016.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[11/169] test0018.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[12/169] test0021.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[13/169] test0025.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[14/169] test0026.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[15/169] test0027.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[16/169] test0029.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[17/169] test0031.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[18/169] test0032.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[19/169] test0039.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[20/169] test0042.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "   Saving Stage 2 checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[21/169] test0044.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[22/169] test0045.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[23/169] test0046.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[24/169] test0047.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[25/169] test0048.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[26/169] test0050.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[27/169] test0051.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[28/169] test0052.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[29/169] test0053.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[30/169] test0054.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[31/169] test0055.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[32/169] test0056.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[33/169] test0058.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[34/169] test0059.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[35/169] test0060.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[36/169] test0063.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[37/169] test0064.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[38/169] test0065.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[39/169] test0066.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[40/169] test0067.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "   Saving Stage 2 checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[41/169] test0068.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[42/169] test0072.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[43/169] test0073.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[44/169] test0074.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[45/169] test0078.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[46/169] test0086.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[47/169] test0092.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[48/169] test0093.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[49/169] test0096.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[50/169] test0097.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[51/169] test0098.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[52/169] test0102.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[53/169] test0103.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[54/169] test0105.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[55/169] test0106.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[56/169] test0107.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[57/169] test0108.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[58/169] test0110.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[59/169] test0111.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[60/169] test0112.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "   Saving Stage 2 checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[61/169] test0114.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[62/169] test0116.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[63/169] test0118.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[64/169] test0119.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[65/169] test0122.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[66/169] test0125.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[67/169] test0126.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[68/169] test0128.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[69/169] test0129.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[70/169] test0131.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[71/169] test0133.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[72/169] test0135.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[73/169] test0137.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[74/169] test0138.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[75/169] test0141.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[76/169] test0142.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[77/169] test0143.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[78/169] test0144.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[79/169] test0147.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[80/169] test0148.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "   Saving Stage 2 checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[81/169] test0153.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[82/169] test0156.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[83/169] test0157.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[84/169] test0161.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[85/169] test0162.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[86/169] test0164.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[87/169] test0165.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[88/169] test0167.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[89/169] test0171.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[90/169] test0172.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[91/169] test0174.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[92/169] test0177.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[93/169] test0178.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[94/169] test0182.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[95/169] test0184.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[96/169] test0187.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[97/169] test0188.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[98/169] test0189.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[99/169] test0192.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[100/169] test0195.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "   Saving Stage 2 checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[101/169] test0196.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[102/169] test0198.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[103/169] test0199.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[104/169] test0200.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[105/169] test0201.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[106/169] test0203.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[107/169] test0205.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[108/169] test0206.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[109/169] test0208.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[110/169] test0209.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[111/169] test0210.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[112/169] test0214.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[113/169] test0216.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[114/169] test0220.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[115/169] test0221.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[116/169] test0224.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[117/169] test0225.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[118/169] test0227.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[119/169] test0228.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[120/169] test0229.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "   Saving Stage 2 checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[121/169] test0231.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[122/169] test0238.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[123/169] test0239.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[124/169] test0240.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[125/169] test0241.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[126/169] test0244.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[127/169] test0245.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[128/169] test0247.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[129/169] test0249.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[130/169] test0250.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[131/169] test0251.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[132/169] test0253.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[133/169] test0254.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[134/169] test0255.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[135/169] test0256.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[136/169] test0257.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[137/169] test0263.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[138/169] test0264.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[139/169] test0267.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[140/169] test0269.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[141/169] test0272.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[142/169] test0273.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[143/169] test0274.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[144/169] test0275.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[145/169] test0278.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[146/169] test0280.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[147/169] test0283.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[148/169] test0284.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[149/169] test0289.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[150/169] test0290.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[151/169] test0291.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[152/169] test0293.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[153/169] test0295.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[154/169] test0296.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[155/169] test0298.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[156/169] test0300.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[157/169] test0301.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[158/169] test0303.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[159/169] test0306.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[160/169] test0311.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "   Saving Stage 2 checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[161/169] test0315.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[162/169] test0316.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[163/169] test0320.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[164/169] test0321.jpg\n",
      "   Current: NonPolitical\n",
      "   Skipped: Contains non-political keyword (bkash/বিকাশ)\n",
      "\n",
      "[165/169] test0325.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[166/169] test0326.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[167/169] test0327.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[168/169] test0328.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "[169/169] test0330.jpg\n",
      "   Current: NonPolitical\n",
      "   Validating with Phi-3-Vision...\n",
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error: 'DynamicCache' object has no attribute 'get_max_le\n",
      "\n",
      "======================================================================\n",
      "STAGE 2 VALIDATION COMPLETE!\n",
      "======================================================================\n",
      "   Text-based Political changes: 6\n",
      "   Text-based NonPolitical changes: 1\n",
      "   Visual validation changes: 0\n",
      "   Total changes: 7\n",
      "\n",
      "Unloading model...\n",
      "Model unloaded and memory cleared!\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Execute Stage 2 Validation\n",
    "\n",
    "print(\"Starting Stage 2: Keyword-Based Validation\")\n",
    "print(\"This will validate NonPolitical predictions for political content...\\n\")\n",
    "\n",
    "results_df = run_stage2_validation(\n",
    "    results_df=results_df,\n",
    "    image_dir=IMAGE_DIR,\n",
    "    stage2_checkpoint_path=STAGE2_CHECKPOINT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaaae1f",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Submission\n",
    "### Final Statistics\n",
    "Display final label distribution and prediction summary after both stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9177444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:09:36.764090Z",
     "iopub.status.busy": "2025-12-05T10:09:36.763643Z",
     "iopub.status.idle": "2025-12-05T10:09:36.773875Z",
     "shell.execute_reply": "2025-12-05T10:09:36.773072Z",
     "shell.execute_reply.started": "2025-12-05T10:09:36.764070Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL STATISTICS (AFTER STAGE 2)\n",
      "============================================================\n",
      "\n",
      "Completion:\n",
      "   Total images: 330\n",
      "   Predicted: 330\n",
      "   Completion rate: 100.0%\n",
      "\n",
      "Final Label Distribution:\n",
      "   NonPolitical: 169 (51.2%)\n",
      "   Political: 161 (48.8%)\n",
      "\n",
      "Sample Predictions:\n",
      "   test0001.jpg: Political\n",
      "   test0002.jpg: NonPolitical\n",
      "   test0003.jpg: Political\n",
      "   test0004.jpg: Political\n",
      "   test0005.jpg: NonPolitical\n",
      "   test0006.jpg: Political\n",
      "   test0007.jpg: NonPolitical\n",
      "   test0008.jpg: Political\n",
      "   test0009.jpg: NonPolitical\n",
      "   test0010.jpg: NonPolitical\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Final Statistics After Both Stages\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL STATISTICS (AFTER STAGE 2)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total = len(results_df)\n",
    "filled = (results_df['Predicted_Label'].notna()) & (results_df['Predicted_Label'] != '')\n",
    "filled_count = filled.sum()\n",
    "\n",
    "print(f\"\\nCompletion:\")\n",
    "print(f\"   Total images: {total}\")\n",
    "print(f\"   Predicted: {filled_count}\")\n",
    "print(f\"   Completion rate: {filled_count/total*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nFinal Label Distribution:\")\n",
    "label_counts = results_df['Predicted_Label'].value_counts()\n",
    "for label, count in label_counts.items():\n",
    "    if label and pd.notna(label):\n",
    "        print(f\"   {label}: {count} ({count/total*100:.1f}%)\")\n",
    "\n",
    "# Display sample results\n",
    "print(f\"\\nSample Predictions:\")\n",
    "for idx, row in results_df.head(10).iterrows():\n",
    "    print(f\"   {row['Image_name']}: {row['Predicted_Label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bb725",
   "metadata": {},
   "source": [
    "### Handle Empty Predictions\n",
    "Apply fallback logic for any remaining empty predictions using political intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e35a307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:09:36.775017Z",
     "iopub.status.busy": "2025-12-05T10:09:36.774758Z",
     "iopub.status.idle": "2025-12-05T10:09:36.794053Z",
     "shell.execute_reply": "2025-12-05T10:09:36.793406Z",
     "shell.execute_reply.started": "2025-12-05T10:09:36.774995Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No empty predictions!\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Handle Any Remaining Empty Predictions\n",
    "\n",
    "empty_mask = (results_df['Predicted_Label'].isna()) | (results_df['Predicted_Label'] == '')\n",
    "empty_count = empty_mask.sum()\n",
    "\n",
    "if empty_count > 0:\n",
    "    print(f\"Warning: {empty_count} predictions still empty. Applying fallback logic...\")\n",
    "    \n",
    "    for idx in results_df[empty_mask].index:\n",
    "        row = results_df.loc[idx]\n",
    "        \n",
    "        # Get context\n",
    "        intensity = str(row.get('Political_Intensity', '')).lower().strip()\n",
    "        metaphor_obj = str(row.get('Metaphor_Object', '')).lower()\n",
    "        explanation = str(row.get('Meme_Explanation', '')).lower()\n",
    "        \n",
    "        # Check for keywords in all text\n",
    "        all_text = f\"{metaphor_obj} {explanation}\"\n",
    "        has_keywords, _ = check_keywords_in_text(all_text, POLITICAL_KEYWORDS)\n",
    "        \n",
    "        # Decision logic\n",
    "        if has_keywords or intensity == 'high':\n",
    "            label = 'Political'\n",
    "        elif intensity == 'low':\n",
    "            label = 'NonPolitical'\n",
    "        else:\n",
    "            label = 'NonPolitical'\n",
    "        \n",
    "        results_df.loc[idx, 'Predicted_Label'] = label\n",
    "        results_df.loc[idx, 'Reasoning'] = f'Fallback: intensity={intensity}'\n",
    "        print(f\"   {row['Image_name']}: {label} (fallback)\")\n",
    "    \n",
    "    print(f\"\\nAll empty predictions filled!\")\n",
    "else:\n",
    "    print(\"No empty predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd17f1e",
   "metadata": {},
   "source": [
    "### Create Submission CSV\n",
    "Generate final submission file with Image_name and Label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "811fad9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:09:36.794959Z",
     "iopub.status.busy": "2025-12-05T10:09:36.794715Z",
     "iopub.status.idle": "2025-12-05T10:09:36.825315Z",
     "shell.execute_reply": "2025-12-05T10:09:36.824757Z",
     "shell.execute_reply.started": "2025-12-05T10:09:36.794939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING FINAL SUBMISSION FILE\n",
      "============================================================\n",
      "\n",
      "Submission saved to: /kaggle/working/submission.csv\n",
      "Total records: 330\n",
      "Columns: ['Image_name', 'Label']\n",
      "\n",
      "Final Label Distribution:\n",
      "Label\n",
      "NonPolitical    169\n",
      "Political       161\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0001.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test0002.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test0003.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test0004.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test0005.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test0006.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test0007.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test0008.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test0009.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test0010.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_name         Label\n",
       "0  test0001.jpg     Political\n",
       "1  test0002.jpg  NonPolitical\n",
       "2  test0003.jpg     Political\n",
       "3  test0004.jpg     Political\n",
       "4  test0005.jpg  NonPolitical\n",
       "5  test0006.jpg     Political\n",
       "6  test0007.jpg  NonPolitical\n",
       "7  test0008.jpg     Political\n",
       "8  test0009.jpg  NonPolitical\n",
       "9  test0010.jpg  NonPolitical"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>test0321.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>test0322.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>test0323.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>test0324.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>test0325.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>test0326.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>test0327.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>test0328.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>test0329.jpg</td>\n",
       "      <td>Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>test0330.jpg</td>\n",
       "      <td>NonPolitical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Image_name         Label\n",
       "320  test0321.jpg  NonPolitical\n",
       "321  test0322.jpg     Political\n",
       "322  test0323.jpg     Political\n",
       "323  test0324.jpg     Political\n",
       "324  test0325.jpg  NonPolitical\n",
       "325  test0326.jpg  NonPolitical\n",
       "326  test0327.jpg  NonPolitical\n",
       "327  test0328.jpg  NonPolitical\n",
       "328  test0329.jpg     Political\n",
       "329  test0330.jpg  NonPolitical"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 18: Create Final Submission CSV\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING FINAL SUBMISSION FILE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = results_df[['Image_name', 'Predicted_Label']].copy()\n",
    "submission_df.columns = ['Image_name', 'Label']\n",
    "\n",
    "# Ensure no empty labels\n",
    "empty_labels = submission_df['Label'].isna() | (submission_df['Label'] == '')\n",
    "if empty_labels.sum() > 0:\n",
    "    print(f\"Warning: Found {empty_labels.sum()} empty labels, filling with NonPolitical...\")\n",
    "    submission_df.loc[empty_labels, 'Label'] = 'NonPolitical'\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved to: {SUBMISSION_PATH}\")\n",
    "print(f\"Total records: {len(submission_df)}\")\n",
    "print(f\"Columns: {submission_df.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\nFinal Label Distribution:\")\n",
    "print(submission_df['Label'].value_counts())\n",
    "\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "display(submission_df.head(10))\n",
    "\n",
    "print(f\"\\nLast 10 rows:\")\n",
    "display(submission_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c879220",
   "metadata": {},
   "source": [
    "### Verify Submission\n",
    "Validate submission format, check for missing/invalid labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f60ebf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:09:36.826366Z",
     "iopub.status.busy": "2025-12-05T10:09:36.826062Z",
     "iopub.status.idle": "2025-12-05T10:09:36.837496Z",
     "shell.execute_reply": "2025-12-05T10:09:36.836787Z",
     "shell.execute_reply.started": "2025-12-05T10:09:36.826347Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUBMISSION VERIFICATION\n",
      "============================================================\n",
      "\n",
      "File: /kaggle/working/submission.csv\n",
      "Shape: (330, 2)\n",
      "Columns: ['Image_name', 'Label']\n",
      "\n",
      "Value counts:\n",
      "Label\n",
      "NonPolitical    169\n",
      "Political       161\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Submission file is valid!\n",
      "Ready for submission!\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Verify Submission Format\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SUBMISSION VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Reload and verify\n",
    "verify_df = pd.read_csv(SUBMISSION_PATH)\n",
    "\n",
    "print(f\"\\nFile: {SUBMISSION_PATH}\")\n",
    "print(f\"Shape: {verify_df.shape}\")\n",
    "print(f\"Columns: {verify_df.columns.tolist()}\")\n",
    "print(f\"\\nValue counts:\")\n",
    "print(verify_df['Label'].value_counts())\n",
    "\n",
    "# Check for issues\n",
    "issues = []\n",
    "\n",
    "if len(verify_df.columns) != 2:\n",
    "    issues.append(f\"Expected 2 columns, got {len(verify_df.columns)}\")\n",
    "\n",
    "if 'Image_name' not in verify_df.columns:\n",
    "    issues.append(\"Missing 'Image_name' column\")\n",
    "\n",
    "if 'Label' not in verify_df.columns:\n",
    "    issues.append(\"Missing 'Label' column\")\n",
    "\n",
    "empty_labels = verify_df['Label'].isna().sum() + (verify_df['Label'] == '').sum()\n",
    "if empty_labels > 0:\n",
    "    issues.append(f\"{empty_labels} empty labels\")\n",
    "\n",
    "invalid_labels = ~verify_df['Label'].isin(['Political', 'NonPolitical'])\n",
    "if invalid_labels.sum() > 0:\n",
    "    issues.append(f\"{invalid_labels.sum()} invalid labels\")\n",
    "    print(f\"\\nInvalid labels found:\")\n",
    "    print(verify_df[invalid_labels]['Label'].unique())\n",
    "\n",
    "if issues:\n",
    "    print(f\"\\nIssues found:\")\n",
    "    for issue in issues:\n",
    "        print(f\"   {issue}\")\n",
    "else:\n",
    "    print(f\"\\nSubmission file is valid!\")\n",
    "    print(\"Ready for submission!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c782433",
   "metadata": {},
   "source": [
    "### Save Full Results\n",
    "Save complete results with reasoning from both stages for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bc20ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:09:36.838565Z",
     "iopub.status.busy": "2025-12-05T10:09:36.838267Z",
     "iopub.status.idle": "2025-12-05T10:09:36.860004Z",
     "shell.execute_reply": "2025-12-05T10:09:36.859452Z",
     "shell.execute_reply.started": "2025-12-05T10:09:36.838544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full results saved to: /kaggle/working/full_results_2stage.csv\n",
      "Contains: 330 records with reasoning from both stages\n"
     ]
    }
   ],
   "source": [
    "# Cell 20: Save Full Results with Reasoning\n",
    "\n",
    "full_results_path = f\"{OUTPUT_DIR}/full_results_2stage.csv\"\n",
    "results_df.to_csv(full_results_path, index=False)\n",
    "\n",
    "print(f\"Full results saved to: {full_results_path}\")\n",
    "print(f\"Contains: {len(results_df)} records with reasoning from both stages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c91591",
   "metadata": {},
   "source": [
    "### Cleanup (Optional)\n",
    "Uncomment to clear /kaggle/working directory if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2fa79d4-128a-41e1-a07a-b74327a7f555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:09:36.860929Z",
     "iopub.status.busy": "2025-12-05T10:09:36.860716Z",
     "iopub.status.idle": "2025-12-05T10:09:36.864378Z",
     "shell.execute_reply": "2025-12-05T10:09:36.863633Z",
     "shell.execute_reply.started": "2025-12-05T10:09:36.860913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# work_dir = \"/kaggle/working\"\n",
    "\n",
    "# # Remove everything inside /kaggle/working\n",
    "# for item in os.listdir(work_dir):\n",
    "#     item_path = os.path.join(work_dir, item)\n",
    "#     try:\n",
    "#         if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "#             os.unlink(item_path)   # delete file or symlink\n",
    "#         elif os.path.isdir(item_path):\n",
    "#             shutil.rmtree(item_path)   # delete folder\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not delete {item_path}: {e}\")\n",
    "\n",
    "# print(\"✔ /kaggle/working directory cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3b305",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Done!\n",
    "\n",
    "### Two-Stage Classification Complete:\n",
    "\n",
    "**Stage 1**: Qwen2.5-VL-7B initial classification\n",
    "- General political/non-political classification\n",
    "- Uses meme context and metadata\n",
    "\n",
    "**Stage 2**: Phi-3-Vision-128k-Instruct keyword validation\n",
    "- **Knowledge base injected** for political content detection\n",
    "- Text-based keyword detection in all columns\n",
    "- Visual validation for political figures and logos\n",
    "- Only changes NonPolitical → Political when political content found\n",
    "- Changes Political → NonPolitical when non-political keywords found (e.g., bKash)\n",
    "\n",
    "### Files Generated:\n",
    "1. **`/kaggle/working/submission.csv`** - Final submission (Image_name, Label)\n",
    "2. **`/kaggle/working/prediction_checkpoint.csv`** - Stage 1 results\n",
    "3. **`/kaggle/working/stage2_checkpoint.csv`** - Stage 2 validation results\n",
    "4. **`/kaggle/working/full_results_2stage.csv`** - Complete results with reasoning\n",
    "\n",
    "### Political Keywords Used:\n",
    "\n",
    "**Specific Terms:**\n",
    "- zohran, jahoran (জোহরান)\n",
    "- bimpi (বিম্পি)\n",
    "- পদপ্রার্থী (Candidate/Nominee)\n",
    "- Aamjonota (আমজনতা)\n",
    "- NCP, National Citizen Party\n",
    "- জাতীয়তাবাদী ছাত্র (Nationalist student)\n",
    "\n",
    "**Politicians:**\n",
    "- Sheikh Hasina (শেখ হাসিনা), Hasina (হাসিনা)\n",
    "- Khaleda Zia (খালেদা জিয়া), Khaleda (খালেদা)\n",
    "- Tarek Zia, Tarique Rahman (তারেক জিয়া, তারেক রহমান)\n",
    "- Ershad (এরশাদ)\n",
    "- Bangabandhu (বঙ্গবন্ধু), Mujib (মুজিব)\n",
    "- Zia (জিয়া), Ziaur Rahman (জিয়াউর রহমান)\n",
    "\n",
    "**Political Parties:**\n",
    "- Awami League (আওয়ামী লীগ)\n",
    "- BNP (বিএনপি), Bangladesh Nationalist Party\n",
    "- Jatiya Party (জাতীয় পার্টি)\n",
    "- Jamaat (জামায়াত), Shibir (শিবির)\n",
    "- BCL (ছাত্রলীগ), Chhatra League\n",
    "- Chhatra Dal (ছাত্রদল)\n",
    "\n",
    "**Political Symbols:**\n",
    "- নৌকা / nouka / boat logo (Awami League)\n",
    "- ধানের শীষ / sheaf of paddy (BNP)\n",
    "- লাঙ্গল / plough (Jatiya Party)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14664749,
     "isSourceIdPinned": false,
     "sourceId": 124686,
     "sourceType": "competition"
    },
    {
     "datasetId": 8877576,
     "sourceId": 14006309,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
